{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Asignatura**: Extensiones de Machine Learning, 2024/2025\n",
    "\n",
    "**Alumnos**:<br>\n",
    "- Gonzalo Marcos Andrés (gonzalo.marcosa@um.es)\n",
    "- Francisco José López Fernández (franciscojose.lopezf@um.es)\n",
    "\n",
    "**Máster de Inteligencia Artificial**\n",
    "\n",
    "| **Facultad de Informática** | **Universidad de Murcia** |\n",
    "|-----------------------------|---------------------------|\n",
    "| ![](https://www.um.es/image/layout_set_logo?img_id=175281&t=1726728636242) | ![](https://www.um.es/o/um-lr-principal-um-home-theme/images/logo-um.png) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook principal para la práctica 2: prendizaje en entornos complejos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexión al repositorio de gitHub en collab:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!  git clone https://github.com/GonzaloMA-17/RL_FJLGM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd RL_FJLGM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías del entorno:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la implementación y análisis del aprendizaje por refuerzo en este proyecto, es necesario acceder a las carpetas y módulos que contienen la lógica de los agentes y las funciones de visualización de resultados.\n",
    "\n",
    "### 1. **Implementación de los Agentes**\n",
    "Los distintos agentes utilizados en el estudio se encuentran en la carpeta src_agents. La estructura de estos agentes sigue un enfoque basado en herencia, donde todos los métodos comparten una lógica común definida en la clase abstracta Agente. Esta clase se encuentra en el archivo:\n",
    "\n",
    "```bash\n",
    "src_agents/\n",
    "│-- agent.py  # Clase base abstracta para todos los agentes\n",
    "```\n",
    "\n",
    "Todos los demás agentes, como Monte Carlo On-Policy, Monte Carlo Off-Policy, SARSA y Q-Learning, heredan de esta clase y sobrescriben los métodos necesarios según su implementación específica.\n",
    "\n",
    "Para facilitar la importación y el uso de estos agentes en otros módulos, el archivo __init__.py permite estructurar src_agents como un paquete de Python. Gracias a esto, se pueden realizar importaciones de manera más sencilla.\n",
    "\n",
    "\n",
    "### 2. **Generación de Gráficos**\n",
    "Para analizar la evolución de los algoritmos, se generan gráficos de desempeño en términos de recompensas y longitudes de los episodios. Para esto, se utiliza la carpeta src_plotting, donde encontramos la función necesaria para trazar la evolución de la duración de los episodios:\n",
    "\n",
    "```bash\n",
    "src_plotting/\n",
    "│-- plotting.py  # Contiene funciones de visualización de los resultados\n",
    "```\n",
    "\n",
    "En este archivo se encuentra la función plot_episode_lengths, cuya implementación permite representar gráficamente la longitud de los episodios durante el entrenamiento del agente. A continuación, se muestra el código de la función:\n",
    "\n",
    "```python\n",
    "def plot_episode_lengths(episode_lengths, window=50, ax=None,\n",
    "                         label_episode=\"Longitud de episodio\",\n",
    "                         label_trend=\"Tendencia (Media Móvil)\"):\n",
    "    \"\"\"\n",
    "    Grafica la longitud de los episodios a lo largo del entrenamiento.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    episode_lengths : list\n",
    "        Lista con las longitudes de cada episodio.\n",
    "    window : int, opcional (por defecto 50)\n",
    "        Tamaño de la ventana para calcular la media móvil.\n",
    "    ax : matplotlib.axes.Axes, opcional\n",
    "        Eje donde se dibujará el gráfico. Si es None, se crea una figura nueva.\n",
    "    label_episode : str, opcional\n",
    "        Etiqueta para la curva principal (longitud de episodio).\n",
    "    label_trend : str, opcional\n",
    "        Etiqueta para la curva de la media móvil (tendencia).\n",
    "    \"\"\"\n",
    "    # Si no se especifica un eje, creamos uno nuevo\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "    indices = list(range(len(episode_lengths)))\n",
    "    ax.plot(indices, episode_lengths, label=label_episode, alpha=0.6)\n",
    "\n",
    "    # Media móvil para suavizar la curva\n",
    "    if len(episode_lengths) >= window:\n",
    "        moving_avg = np.convolve(episode_lengths, np.ones(window) / window, mode=\"valid\")\n",
    "        ax.plot(range(window - 1, len(episode_lengths)), moving_avg, \n",
    "                label=label_trend, color='red')\n",
    "\n",
    "    ax.set_title(\"Longitud de los episodios\")\n",
    "    ax.set_xlabel(\"Episodio\")\n",
    "    ax.set_ylabel(\"Longitud\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "```\n",
    "\n",
    "Esta función toma la lista de longitudes de los episodios y genera una representación visual del progreso del entrenamiento. Además, incluye una media móvil para suavizar las fluctuaciones y proporcionar una mejor interpretación de la tendencia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repuesta a la pregunta de ¿Por qué esta gráfica también es un buen indicador de aprendizaje?\n",
    "\n",
    "\n",
    "La gráfica de la longitud de los episodios es un buen indicador de aprendizaje porque muestra cómo el agente optimiza sus acciones con el tiempo para resolver el entorno de manera más eficiente. A medida que el agente aprende, se espera que la duración de los episodios disminuya y se estabilice, lo que indica que ha encontrado estrategias efectivas para alcanzar su objetivo con menos pasos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}