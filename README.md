# T铆tulo del Trabajo 
## Informaci贸n
- **Alumnos:** L贸pez, Francisco Jos茅; Marcos, Gonzalo; 
- **Asignatura:** Extensiones de Machine Learning
- **Curso:** 2024/2025
- **Grupo:** FJLGM

## Descripci贸n 
Este trabajo se centra en el estudio y aplicaci贸n de t茅cnicas de aprendizaje por refuerzo (RL) en dos contextos diferentes: el problema del bandido de k-brazos y los entornos complejos utilizando Gymnasium. La pr谩ctica 1 aborda el problema del bandido de k-brazos, explorando diferentes algoritmos como e-greedy, UCB y m茅todos de ascenso de gradiente para maximizar la recompensa acumulada y minimizar el rechazo (regret). En la pr谩ctica 2, se investigan entornos complejos mediante el uso de Gymnasium, implementando algoritmos de aprendizaje como Monte Carlo, SARSA y Q-Learning en entornos tabulares y de aproximaci贸n. El objetivo principal es comparar y analizar el rendimiento de estos algoritmos en diversos entornos y problemas, proporcionando una comprensi贸n profunda y aplicada de las t茅cnicas de RL.
## Estructura 

```plaintext
|--  src_agents                                    # Carpeta principal que contiene los agentes de Aprendizaje por Refuerzo
|   |--  __init__.py                               # Archivo que convierte el directorio en un paquete de Python
|   |--  agent.py                                  # Clase base para todos los agentes
|   |--  deepQLearning.py                          # Implementaci贸n del agente Deep Q-Learning (DQN)
|   |--  monteCarloOnPolicy.py                     # Implementaci贸n del agente Monte Carlo On-Policy
|   |--  monteCarloOffPolicy.py                    # Implementaci贸n del agente Monte Carlo Off-Policy
|   |--  qLearning.py                              # Implementaci贸n del agente Q-Learning
|   |--  sarsa.py                                  # Implementaci贸n del agente SARSA tabular
|   |--  sarsaSemiGradiente.py                     # Implementaci贸n del agente SARSA Semigradiente
|   |--  politicas.py                              # Definici贸n de pol铆ticas de exploraci贸n como epsilon-greedy y softmax

|--  src_plotting                                  # Carpeta con herramientas de visualizaci贸n de resultados
|   |--  __init__.py                               # Archivo que convierte el directorio en un paquete de Python
|   |--  plotting.py                               # Funciones para graficar recompensas y longitudes de episodios

|--  main.ipynb                                    # Cuaderno principal con la ejecuci贸n general del proyecto
|--  notebook_aproximaciones_4x4.ipynb             # Evaluaci贸n de m茅todos con aproximaci贸n en FrozenLake 4x4
|--  notebook_tabulares_4x4.ipynb                  # Evaluaci贸n de m茅todos tabulares en FrozenLake 4x4
|--  README.md                                     # Documentaci贸n general del proyecto
|--  requirements.txt                              # Lista de dependencias necesarias para ejecutar el proyecto
```

## Instalaci贸n y Uso 
Para instalar y utilizar este proyecto, sigue los siguientes pasos:
1潞 Clonar el repositorio
```bash
git clone https://github.com/GonzaloMA-17/RL_FJLGM.git
```  

2潞 Navega al directorio del proyecto:
```bash
cd RL_FJLGM
```  

3潞 Instalar todas las dependecias
```bash
pip install -r requirements.txt
```  

4潞 Ejecutar los scripts o notebooks necesarios

## Tecnolog铆as Utilizadas 
Este proyecto utiliza las siguientes tecnolog铆as:

- Lenguajes: Python
- Herramientas: Jupyter Notebook, NumPy, Pandas, Matplotlib
- Entornos: VSCode (entornos virtuales locales), Google Colab.
